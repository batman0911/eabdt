{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "import util\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/linhnm/msc_code/big_data_mining/eabdt/python\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "model_path = '../model/torch_logistic_regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda:0'\n",
    "  print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mix'\n",
    "\n",
    "training_batch_from = 0\n",
    "training_batch_to = 2000\n",
    "val_batch_from = 3000\n",
    "val_batch_to = 3600\n",
    "\n",
    "testing_batch_from = 0\n",
    "testing_batch_to = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "trigger = 1000\n",
    "early_stopping_round = 20\n",
    "\n",
    "input_dim = 384\n",
    "output_dim = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super(LogisticRegression, self).__init__()\n",
    "    self.linear = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    outputs = torch.sigmoid(self.linear(x))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=384, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=384, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = util.load_vector(os.path.join(cwd, '../data/vectorize/mix/testing_set'), testing_batch_from, testing_batch_to)\n",
    "y_test = util.load_label(os.path.join(cwd, '../data/raw/mix/testing_set'), testing_batch_from, testing_batch_to)\n",
    "\n",
    "X_gpu_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_gpu_test = torch.flatten(torch.tensor(y_test).type(torch.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0297, -0.0425,  0.0579,  ..., -0.0358, -0.0148, -0.1152],\n",
       "        [-0.0629,  0.0458,  0.0021,  ..., -0.0511,  0.0432, -0.0235],\n",
       "        [-0.0997,  0.0008, -0.0115,  ..., -0.0179, -0.0186,  0.0597],\n",
       "        ...,\n",
       "        [-0.0708, -0.0321, -0.0142,  ...,  0.0142,  0.0859,  0.0578],\n",
       "        [-0.0387, -0.0754,  0.0961,  ...,  0.0431, -0.0230,  0.0405],\n",
       "        [-0.0274, -0.0936, -0.0093,  ...,  0.0515, -0.0042, -0.0122]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gpu_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_test = 0\n",
    "total_test = 0\n",
    "outputs_test = torch.squeeze(model(X_gpu_test))\n",
    "loss_test = criterion(outputs_test, y_gpu_test)\n",
    "\n",
    "total_test += y_gpu_test.size(0)\n",
    "correct_test += torch.eq(outputs_test.round(), y_gpu_test).sum()\n",
    "accuracy_test = 100 * correct_test/total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.36325073242188\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_test.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
