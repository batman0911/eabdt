{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "import util\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/linhnm/msc_code/big_data_mining/eabdt/python\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "model_path_lg = '../model/torch_logistic_regression'\n",
    "model_path_sm_384 = '../model/torch_softmax_sgd_384'\n",
    "model_path_sm_768 = '../model/torch_softmax_sgd_768'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda:0'\n",
    "  print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mix'\n",
    "\n",
    "training_batch_from = 0\n",
    "training_batch_to = 2000\n",
    "val_batch_from = 3000\n",
    "val_batch_to = 3600\n",
    "\n",
    "testing_batch_from = 0\n",
    "testing_batch_to = 400\n",
    "\n",
    "testing_768_batch_from = 0\n",
    "testing_768_batch_to = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "trigger = 1000\n",
    "early_stopping_round = 20\n",
    "\n",
    "input_dim = 384\n",
    "output_dim = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super(LogisticRegression, self).__init__()\n",
    "    self.linear = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    outputs = torch.sigmoid(self.linear(x))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super(Softmax, self).__init__()\n",
    "    # hidden layer \n",
    "    self.linear_1 = torch.nn.Linear(input_dim, 128, bias=True)\n",
    "    self.linear_2 = torch.nn.Linear(128, 64, bias=True) \n",
    "    self.linear_3 = torch.nn.Linear(64, output_dim) \n",
    "    # defining layers as attributes\n",
    "    self.layer_in = None\n",
    "    self.act = None\n",
    "    self.layer_out = None\n",
    "  def forward(self, x):\n",
    "    self.layer_in_1 = self.linear_1(x)\n",
    "    self.act_1 = torch.relu(self.layer_in_1)\n",
    "    self.layer_in_2 = self.linear_2(self.act_1)\n",
    "    self.act_2 = torch.relu(self.layer_in_2)\n",
    "    self.layer_out = self.linear_3(self.act_2)\n",
    "    y_pred = torch.sigmoid(self.linear_3(self.act_2))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lg = LogisticRegression(input_dim, output_dim)\n",
    "model_sm_384 = Softmax(384, 1)\n",
    "model_sm_768 = Softmax(768, 1)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=384, out_features=1, bias=True)\n",
      ")\n",
      "Softmax(\n",
      "  (linear_1): Linear(in_features=384, out_features=128, bias=True)\n",
      "  (linear_2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear_3): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Softmax(\n",
      "  (linear_1): Linear(in_features=768, out_features=128, bias=True)\n",
      "  (linear_2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear_3): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_lg.load_state_dict(torch.load(model_path_lg))\n",
    "model_sm_384.load_state_dict(torch.load(model_path_sm_384))\n",
    "model_sm_768.load_state_dict(torch.load(model_path_sm_768))\n",
    "\n",
    "print(model_lg.eval())\n",
    "print(model_sm_384.eval())\n",
    "print(model_sm_768.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Softmax(\n",
       "  (linear_1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (linear_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear_3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sm_384.to(device)\n",
    "model_sm_768.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = util.load_vector(os.path.join(cwd, '../data/vectorize/384/mix/testing_set'), testing_batch_from, testing_batch_to)\n",
    "y_test = util.load_label(os.path.join(cwd, '../data/raw/mix/testing_set'), testing_batch_from, testing_batch_to)\n",
    "\n",
    "X_768_test = util.load_vector(os.path.join(cwd, '../data/vectorize/mix/testing_set'), testing_768_batch_from, testing_768_batch_to)\n",
    "y_768_test = util.load_label(os.path.join(cwd, '../data/raw/mix/testing_set'), testing_768_batch_from, testing_768_batch_to)\n",
    "\n",
    "X_gpu_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_gpu_test = torch.flatten(torch.tensor(y_test).type(torch.float32)).to(device)\n",
    "\n",
    "X_768_gpu_test = torch.tensor(X_768_test, dtype=torch.float32).to(device)\n",
    "y_768_gpu_test = torch.flatten(torch.tensor(y_768_test).type(torch.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0297, -0.0425,  0.0579,  ..., -0.0358, -0.0148, -0.1152],\n",
       "        [-0.0629,  0.0458,  0.0021,  ..., -0.0511,  0.0432, -0.0235],\n",
       "        [-0.0997,  0.0008, -0.0115,  ..., -0.0179, -0.0186,  0.0597],\n",
       "        ...,\n",
       "        [-0.0708, -0.0321, -0.0142,  ...,  0.0142,  0.0859,  0.0578],\n",
       "        [-0.0387, -0.0754,  0.0961,  ...,  0.0431, -0.0230,  0.0405],\n",
       "        [-0.0274, -0.0936, -0.0093,  ...,  0.0515, -0.0042, -0.0122]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gpu_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gpu_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_test = 0\n",
    "# total_test = 0\n",
    "# outputs_test = torch.squeeze(model_lg(X_gpu_test))\n",
    "# loss_test = criterion(outputs_test, y_gpu_test)\n",
    "\n",
    "# total_test += y_gpu_test.size(0)\n",
    "# correct_test += torch.eq(outputs_test.round(), y_gpu_test).sum()\n",
    "# accuracy_test = 100 * correct_test/total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accuracy_test.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sm_384, auc_sm_384 = util.metrics(model_sm_384, criterion,  X_gpu_test, y_gpu_test)\n",
    "acc_sm_768, auc_sm_768 = util.metrics(model_sm_768, criterion,  X_768_gpu_test, y_768_gpu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.729248046875 0.9619949044125\n",
      "91.82500457763672 0.9714606467587035\n"
     ]
    }
   ],
   "source": [
    "print(acc_sm_384, auc_sm_384)\n",
    "print(acc_sm_768, auc_sm_768)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
