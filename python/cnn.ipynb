{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler, SequentialSampler)\n",
    "\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "import util\n",
    "import os \n",
    "\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/linhnm/msc_code/big_data_mining/eabdt/python\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mix'\n",
    "\n",
    "training_batch_from = 0\n",
    "training_batch_to = 2000\n",
    "val_batch_from = 3000\n",
    "val_batch_to = 3600\n",
    "\n",
    "testing_batch_from = 0\n",
    "testing_batch_to = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda:0'\n",
    "  print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = util.load_vector(os.path.join(cwd, '../data/vectorize/mix/training_set'), training_batch_from, training_batch_to)\n",
    "y_train = util.load_label(os.path.join(cwd, '../data/raw/mix/training_set'), training_batch_from, training_batch_to)\n",
    "\n",
    "X_val = util.load_vector(os.path.join(cwd, '../data/vectorize/mix/training_set'), val_batch_from, val_batch_to)\n",
    "y_val = util.load_label(os.path.join(cwd, '../data/raw/mix/training_set'), val_batch_from, val_batch_to)\n",
    "\n",
    "X_test = util.load_vector(os.path.join(cwd, '../data/vectorize/mix/testing_set'), testing_batch_from, testing_batch_to)\n",
    "y_test = util.load_label(os.path.join(cwd, '../data/raw/mix/testing_set'), testing_batch_from, testing_batch_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_gpu_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "# y_gpu_train = torch.flatten(torch.tensor(y_train).type(torch.float32)).to(device)\n",
    "# X_gpu_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "# y_gpu_val = torch.flatten(torch.tensor(y_val).type(torch.float32)).to(device)\n",
    "# X_gpu_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "# y_gpu_test = torch.flatten(torch.tensor(y_test).type(torch.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "trigger = 1000\n",
    "early_stopping_round = 20\n",
    "\n",
    "input_dim = 384\n",
    "output_dim = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(train_inputs, val_inputs, train_labels, val_labels,\n",
    "                batch_size=50):\n",
    "    \"\"\"Convert train and validation sets to torch.Tensors and load them to\n",
    "    DataLoader.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert data type to torch.Tensor\n",
    "    train_inputs, val_inputs, train_labels, val_labels =\\\n",
    "    tuple(torch.tensor(data) for data in\n",
    "          [train_inputs, val_inputs, train_labels, val_labels])\n",
    "\n",
    "    # Specify batch_size\n",
    "    batch_size = 50\n",
    "\n",
    "    # Create DataLoader for training data\n",
    "    train_data = TensorDataset(train_inputs, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # Create DataLoader for validation data\n",
    "    val_data = TensorDataset(val_inputs, val_labels)\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = data_loader(X_train, X_val, y_train, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_NLP(nn.Module):\n",
    "    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n",
    "    def __init__(self,\n",
    "                 pretrained_embedding=None,\n",
    "                 freeze_embedding=False,\n",
    "                 vocab_size=None,\n",
    "                 embed_dim=input_dim,\n",
    "                 filter_sizes=[3, 4, 5],\n",
    "                 num_filters=[100, 100, 100],\n",
    "                 num_classes=2,\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        The constructor for CNN_NLP class.\n",
    "\n",
    "        Args:\n",
    "            pretrained_embedding (torch.Tensor): Pretrained embeddings with\n",
    "                shape (vocab_size, embed_dim)\n",
    "            freeze_embedding (bool): Set to False to fine-tune pretraiend\n",
    "                vectors. Default: False\n",
    "            vocab_size (int): Need to be specified when not pretrained word\n",
    "                embeddings are not used.\n",
    "            embed_dim (int): Dimension of word vectors. Need to be specified\n",
    "                when pretrained word embeddings are not used. Default: 300\n",
    "            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n",
    "            num_filters (List[int]): List of number of filters, has the same\n",
    "                length as `filter_sizes`. Default: [100, 100, 100]\n",
    "            n_classes (int): Number of classes. Default: 2\n",
    "            dropout (float): Dropout rate. Default: 0.5\n",
    "        \"\"\"\n",
    "\n",
    "        super(CNN_NLP, self).__init__()\n",
    "        # Embedding layer\n",
    "        # if pretrained_embedding is not None:\n",
    "        #     self.vocab_size, self.embed_dim = pretrained_embedding.shape\n",
    "        #     self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n",
    "        #                                                   freeze=freeze_embedding)\n",
    "        # else:\n",
    "        #     self.embed_dim = embed_dim\n",
    "        #     self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "        #                                   embedding_dim=self.embed_dim,\n",
    "        #                                   padding_idx=0,\n",
    "        #                                   max_norm=5.0)\n",
    "        self.embed_dim = input_dim\n",
    "        # Conv Network\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.embed_dim,\n",
    "                      out_channels=num_filters[i],\n",
    "                      kernel_size=filter_sizes[i])\n",
    "            for i in range(len(filter_sizes))\n",
    "        ])\n",
    "        # Fully-connected layer and Dropout\n",
    "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in_dim = x.shape[0]\n",
    "\n",
    "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
    "        # x_embed = self.embedding(input_ids).float()\n",
    "\n",
    "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
    "        # Output shape: (b, embed_dim, max_len)\n",
    "        d1 = x.shape[0]\n",
    "        d2 = x.shape[1]\n",
    "        x_reshaped = x.reshape(d1*d2).reshape(d1, d2, 1)\n",
    "        # xt = x.reshape(d1, d2, 1)\n",
    "        # x_reshaped = xt.permute(0, 2, 1)\n",
    "\n",
    "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
    "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
    "\n",
    "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
    "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
    "            for x_conv in x_conv_list]\n",
    "        \n",
    "        # Concatenate x_pool_list to feed the fully connected layer.\n",
    "        # Output shape: (b, sum(num_filters))\n",
    "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
    "                         dim=1)\n",
    "        \n",
    "        # Compute logits. Output shape: (b, n_classes)\n",
    "        logits = self.fc(self.dropout(x_fc))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilize_model(pretrained_embedding=None,\n",
    "                    freeze_embedding=False,\n",
    "                    vocab_size=None,\n",
    "                    embed_dim=input_dim,\n",
    "                    filter_sizes=[3, 4, 5],\n",
    "                    num_filters=[100, 100, 100],\n",
    "                    num_classes=2,\n",
    "                    dropout=0.5,\n",
    "                    learning_rate=0.01):\n",
    "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
    "\n",
    "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
    "    num_filters need to be of the same length.\"\n",
    "\n",
    "    # Instantiate CNN model\n",
    "    cnn_model = CNN_NLP(pretrained_embedding=pretrained_embedding,\n",
    "                        freeze_embedding=freeze_embedding,\n",
    "                        vocab_size=vocab_size,\n",
    "                        embed_dim=input_dim,\n",
    "                        filter_sizes=filter_sizes,\n",
    "                        num_filters=num_filters,\n",
    "                        num_classes=2,\n",
    "                        dropout=0.5)\n",
    "    \n",
    "    # Send model to `device` (GPU/CPU)\n",
    "    cnn_model.to(device)\n",
    "\n",
    "    # Instantiate Adadelta optimizer\n",
    "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               rho=0.95)\n",
    "\n",
    "    return cnn_model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, optimizer, train_dataloader, val_dataloader=None, epochs=10):\n",
    "    \"\"\"Train the CNN model.\"\"\"\n",
    "    \n",
    "    # Tracking best validation accuracy\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    print(f'{\"Epoch\":^7} | {\"Train Loss\":^12} | {\"Val Loss\":^10} | {\"Val Acc\":^9} | {\"Elapsed\":^9}')\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "\n",
    "        # Tracking time and loss\n",
    "        t0_epoch = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if val_dataloader is not None:\n",
    "            # After the completion of each training epoch, measure the model's\n",
    "            # performance on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Track the best accuracy\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            \n",
    "    print(\"\\n\")\n",
    "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's\n",
    "    performance on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled\n",
    "    # during the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1). Kernel size: (3). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m set_seed(\u001b[39m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m cnn_static, optimizer \u001b[39m=\u001b[39m initilize_model(pretrained_embedding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m                                         freeze_embedding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                                         embed_dim\u001b[39m=\u001b[39minput_dim,\n\u001b[1;32m      5\u001b[0m                                         learning_rate\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                         dropout\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m train(cnn_static, optimizer, train_dataloader, val_dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[61], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     42\u001b[0m \u001b[39m# Perform a forward pass. This will return logits.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m logits \u001b[39m=\u001b[39m model(b_input_ids)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Compute loss and accumulate the loss values\u001b[39;00m\n\u001b[1;32m     46\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, b_labels)\n",
      "File \u001b[0;32m~/msc_code/big_data_mining/eabdt/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[59], line 70\u001b[0m, in \u001b[0;36mCNN_NLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m x_reshaped \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(d1\u001b[39m*\u001b[39md2)\u001b[39m.\u001b[39mreshape(d1, d2, \u001b[39m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[39m# xt = x.reshape(d1, d2, 1)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m# x_reshaped = xt.permute(0, 2, 1)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[39m# Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m x_conv_list \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mrelu(conv1d(x_reshaped)) \u001b[39mfor\u001b[39;00m conv1d \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1d_list]\n\u001b[1;32m     72\u001b[0m \u001b[39m# Max pooling. Output shape: (b, num_filters[i], 1)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m x_pool_list \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mmax_pool1d(x_conv, kernel_size\u001b[39m=\u001b[39mx_conv\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])\n\u001b[1;32m     74\u001b[0m     \u001b[39mfor\u001b[39;00m x_conv \u001b[39min\u001b[39;00m x_conv_list]\n",
      "Cell \u001b[0;32mIn[59], line 70\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m x_reshaped \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(d1\u001b[39m*\u001b[39md2)\u001b[39m.\u001b[39mreshape(d1, d2, \u001b[39m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[39m# xt = x.reshape(d1, d2, 1)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m# x_reshaped = xt.permute(0, 2, 1)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[39m# Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m x_conv_list \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mrelu(conv1d(x_reshaped)) \u001b[39mfor\u001b[39;00m conv1d \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1d_list]\n\u001b[1;32m     72\u001b[0m \u001b[39m# Max pooling. Output shape: (b, num_filters[i], 1)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m x_pool_list \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mmax_pool1d(x_conv, kernel_size\u001b[39m=\u001b[39mx_conv\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])\n\u001b[1;32m     74\u001b[0m     \u001b[39mfor\u001b[39;00m x_conv \u001b[39min\u001b[39;00m x_conv_list]\n",
      "File \u001b[0;32m~/msc_code/big_data_mining/eabdt/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/msc_code/big_data_mining/eabdt/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/msc_code/big_data_mining/eabdt/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1). Kernel size: (3). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "cnn_static, optimizer = initilize_model(pretrained_embedding=None,\n",
    "                                        freeze_embedding=True,\n",
    "                                        embed_dim=input_dim,\n",
    "                                        learning_rate=0.25,\n",
    "                                        dropout=0.5)\n",
    "train(cnn_static, optimizer, train_dataloader, val_dataloader, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
